{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3e347e",
   "metadata": {},
   "source": [
    "# Bayesian Model on MNIST data\n",
    "\n",
    "<br>\n",
    "\n",
    "- In this tutorial, we will take the MNIST dataset and call it D0 dataset\n",
    "\n",
    "<br>\n",
    "\n",
    "- We will do a 9 dimensional PCA projection and call it as D1 dataset\n",
    "\n",
    "<br>\n",
    "\n",
    "- We do a 9 dimensional FISHER projection and call it D2 dataset\n",
    "\n",
    "<br>\n",
    "\n",
    "- We will then build a Bayesian classifier on D1 (single gaussian per class):\n",
    "-- Take full covariance matrix \n",
    "-- Take diagonal covariance matrix (i.e.set non diagonals to zero)\n",
    "\n",
    "<br>\n",
    "\n",
    "- We will build a Bayesian classifier on D2 (single Gaussian per class) and considering diagonal  covariance matrix.\n",
    "\n",
    "- We will then compare the test accuracies of the two classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e204b",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e3fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split  # splitting dataset in train test data\n",
    "from scipy.stats import multivariate_normal # used in gaussian pdf computation on mnist data.\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2ac93",
   "metadata": {},
   "source": [
    "## Read MNIST data (D0 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf283161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top few rows of dataset:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D0 = pd.read_csv(\"train.csv\") # import digits data\n",
    "print(\"Top few rows of dataset:\\n\")\n",
    "display(D0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db93205",
   "metadata": {},
   "source": [
    "## Implement PCA (D1 Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56899d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "D1 dataset after PCA implementation:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projection0</th>\n",
       "      <th>projection1</th>\n",
       "      <th>projection2</th>\n",
       "      <th>projection3</th>\n",
       "      <th>projection4</th>\n",
       "      <th>projection5</th>\n",
       "      <th>projection6</th>\n",
       "      <th>projection7</th>\n",
       "      <th>projection8</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.140478</td>\n",
       "      <td>-5.226445</td>\n",
       "      <td>3.887001</td>\n",
       "      <td>-0.901512</td>\n",
       "      <td>-4.929111</td>\n",
       "      <td>-2.035413</td>\n",
       "      <td>-4.706946</td>\n",
       "      <td>4.767184</td>\n",
       "      <td>-0.230958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.292332</td>\n",
       "      <td>6.032996</td>\n",
       "      <td>1.308148</td>\n",
       "      <td>-2.383294</td>\n",
       "      <td>-3.095188</td>\n",
       "      <td>1.791095</td>\n",
       "      <td>3.772790</td>\n",
       "      <td>-0.153865</td>\n",
       "      <td>4.115192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.644503</td>\n",
       "      <td>-1.705813</td>\n",
       "      <td>2.289326</td>\n",
       "      <td>2.241135</td>\n",
       "      <td>-5.094426</td>\n",
       "      <td>4.152058</td>\n",
       "      <td>1.012004</td>\n",
       "      <td>-1.732559</td>\n",
       "      <td>-0.436261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.474207</td>\n",
       "      <td>5.836139</td>\n",
       "      <td>2.008617</td>\n",
       "      <td>4.271106</td>\n",
       "      <td>-2.377777</td>\n",
       "      <td>-2.179913</td>\n",
       "      <td>-4.398030</td>\n",
       "      <td>0.353712</td>\n",
       "      <td>-0.992308</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.559574</td>\n",
       "      <td>6.024818</td>\n",
       "      <td>0.933179</td>\n",
       "      <td>-3.012645</td>\n",
       "      <td>-9.489179</td>\n",
       "      <td>2.331195</td>\n",
       "      <td>6.149597</td>\n",
       "      <td>1.783637</td>\n",
       "      <td>4.123302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>13.678849</td>\n",
       "      <td>-1.350366</td>\n",
       "      <td>-3.957336</td>\n",
       "      <td>-5.379672</td>\n",
       "      <td>-10.875898</td>\n",
       "      <td>5.105523</td>\n",
       "      <td>-0.071920</td>\n",
       "      <td>5.084014</td>\n",
       "      <td>4.253677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>-8.869582</td>\n",
       "      <td>-1.187360</td>\n",
       "      <td>2.323167</td>\n",
       "      <td>1.528830</td>\n",
       "      <td>-5.798988</td>\n",
       "      <td>2.821950</td>\n",
       "      <td>0.351780</td>\n",
       "      <td>-0.529810</td>\n",
       "      <td>-0.992204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>0.495391</td>\n",
       "      <td>7.076277</td>\n",
       "      <td>-12.089700</td>\n",
       "      <td>-3.223278</td>\n",
       "      <td>-0.618203</td>\n",
       "      <td>-0.330449</td>\n",
       "      <td>2.128035</td>\n",
       "      <td>-10.535164</td>\n",
       "      <td>2.225962</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>2.307240</td>\n",
       "      <td>-4.344513</td>\n",
       "      <td>0.699848</td>\n",
       "      <td>10.011222</td>\n",
       "      <td>5.586478</td>\n",
       "      <td>5.494875</td>\n",
       "      <td>-0.189789</td>\n",
       "      <td>-5.450360</td>\n",
       "      <td>-2.181693</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>-4.807670</td>\n",
       "      <td>1.559121</td>\n",
       "      <td>-2.497936</td>\n",
       "      <td>2.218724</td>\n",
       "      <td>1.041887</td>\n",
       "      <td>-0.168182</td>\n",
       "      <td>-1.191325</td>\n",
       "      <td>3.285766</td>\n",
       "      <td>1.626590</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       projection0  projection1  projection2  projection3  projection4  \\\n",
       "0        -5.140478    -5.226445     3.887001    -0.901512    -4.929111   \n",
       "1        19.292332     6.032996     1.308148    -2.383294    -3.095188   \n",
       "2        -7.644503    -1.705813     2.289326     2.241135    -5.094426   \n",
       "3        -0.474207     5.836139     2.008617     4.271106    -2.377777   \n",
       "4        26.559574     6.024818     0.933179    -3.012645    -9.489179   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "41995    13.678849    -1.350366    -3.957336    -5.379672   -10.875898   \n",
       "41996    -8.869582    -1.187360     2.323167     1.528830    -5.798988   \n",
       "41997     0.495391     7.076277   -12.089700    -3.223278    -0.618203   \n",
       "41998     2.307240    -4.344513     0.699848    10.011222     5.586478   \n",
       "41999    -4.807670     1.559121    -2.497936     2.218724     1.041887   \n",
       "\n",
       "       projection5  projection6  projection7  projection8  label  \n",
       "0        -2.035413    -4.706946     4.767184    -0.230958      1  \n",
       "1         1.791095     3.772790    -0.153865     4.115192      0  \n",
       "2         4.152058     1.012004    -1.732559    -0.436261      1  \n",
       "3        -2.179913    -4.398030     0.353712    -0.992308      4  \n",
       "4         2.331195     6.149597     1.783637     4.123302      0  \n",
       "...            ...          ...          ...          ...    ...  \n",
       "41995     5.105523    -0.071920     5.084014     4.253677      0  \n",
       "41996     2.821950     0.351780    -0.529810    -0.992204      1  \n",
       "41997    -0.330449     2.128035   -10.535164     2.225962      7  \n",
       "41998     5.494875    -0.189789    -5.450360    -2.181693      6  \n",
       "41999    -0.168182    -1.191325     3.285766     1.626590      9  \n",
       "\n",
       "[42000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"Load MNIST data and perform PCA (784 dimensions to 9 dimensions projected dataframe)\"\n",
    "\n",
    "label_in_data = D0['label']\n",
    "dataval= D0.drop([\"label\"], axis = 1)\n",
    "\n",
    "\n",
    "\"Scale features and compute eigen values and eigen vectors\"\n",
    "scaledfeature = StandardScaler(copy=True, with_mean=True).fit_transform(dataval)  # shape is (4684, 784)\n",
    "cvmat = np.cov(scaledfeature, rowvar = False, bias = False )\n",
    "eigenva, eigenve = np.linalg.eig(cvmat) # input to linalg.eig() from numpy module is square array which is covariance matrix in our case\n",
    "pairs_eigva_eigve = [(np.abs(eigenva[k]), eigenve[:,k]) for k in range(len(eigenva))] # create pairs of eigenvalue and eigenvectors\n",
    "sorting_eig_pairs =sorted(pairs_eigva_eigve, key=lambda eigva: eigva[0], reverse=True) \n",
    "\n",
    "stackedcomp = np.hstack((sorting_eig_pairs[0][1].reshape(784,1), sorting_eig_pairs[1][1].reshape(784,1),\n",
    "                           sorting_eig_pairs[2][1].reshape(784,1), sorting_eig_pairs[3][1].reshape(784,1),\n",
    "                           sorting_eig_pairs[4][1].reshape(784,1), sorting_eig_pairs[5][1].reshape(784,1),\n",
    "                           sorting_eig_pairs[6][1].reshape(784,1), sorting_eig_pairs[7][1].reshape(784,1),\n",
    "                           sorting_eig_pairs[8][1].reshape(784,1)))   \n",
    "\n",
    "\"projected data\"\n",
    "projecteddata = scaledfeature.dot(stackedcomp)  # dot product of projections with originial scaled data\n",
    "\n",
    "colnames = []\n",
    "for i in range(0,9):\n",
    "    colnames.append(\"projection\" + str(i))\n",
    "\n",
    "D1  = pd.DataFrame(data = projecteddata, columns = colnames, dtype = None)\n",
    "D1['label'] = label_in_data  # append label column to projected data frame\n",
    "\n",
    "print(\"\\nD1 dataset after PCA implementation:\\n\")\n",
    "display(D1) #  9 projections with last column as label column \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262fef36",
   "metadata": {},
   "source": [
    "## Implement Fischer Discriminant Analysis - FDA (D2 Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52bcf5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "D2 dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projection0</th>\n",
       "      <th>projection1</th>\n",
       "      <th>projection2</th>\n",
       "      <th>projection3</th>\n",
       "      <th>projection4</th>\n",
       "      <th>projection5</th>\n",
       "      <th>projection6</th>\n",
       "      <th>projection7</th>\n",
       "      <th>projection8</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706982</td>\n",
       "      <td>3.702191</td>\n",
       "      <td>-0.546160</td>\n",
       "      <td>1.083590</td>\n",
       "      <td>-1.282057</td>\n",
       "      <td>-0.640238</td>\n",
       "      <td>-0.161646</td>\n",
       "      <td>0.711746</td>\n",
       "      <td>0.098052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.753373</td>\n",
       "      <td>-3.257093</td>\n",
       "      <td>-2.983682</td>\n",
       "      <td>-1.244001</td>\n",
       "      <td>-1.880934</td>\n",
       "      <td>-0.898564</td>\n",
       "      <td>0.114414</td>\n",
       "      <td>-1.097409</td>\n",
       "      <td>1.235790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.426475</td>\n",
       "      <td>5.168707</td>\n",
       "      <td>-0.215028</td>\n",
       "      <td>0.248895</td>\n",
       "      <td>-3.737808</td>\n",
       "      <td>0.168903</td>\n",
       "      <td>0.546867</td>\n",
       "      <td>0.164058</td>\n",
       "      <td>-0.314798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.978410</td>\n",
       "      <td>-0.555503</td>\n",
       "      <td>1.147945</td>\n",
       "      <td>-0.324528</td>\n",
       "      <td>-0.997568</td>\n",
       "      <td>-0.858390</td>\n",
       "      <td>0.979497</td>\n",
       "      <td>1.846044</td>\n",
       "      <td>-0.207963</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.878184</td>\n",
       "      <td>-3.244367</td>\n",
       "      <td>-4.723876</td>\n",
       "      <td>-0.850046</td>\n",
       "      <td>-1.923177</td>\n",
       "      <td>-2.093587</td>\n",
       "      <td>0.166724</td>\n",
       "      <td>-2.228554</td>\n",
       "      <td>0.999328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>-2.846328</td>\n",
       "      <td>-1.655570</td>\n",
       "      <td>-3.661467</td>\n",
       "      <td>0.658924</td>\n",
       "      <td>-1.528190</td>\n",
       "      <td>-0.680945</td>\n",
       "      <td>0.511808</td>\n",
       "      <td>-1.606290</td>\n",
       "      <td>-1.122931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1.776876</td>\n",
       "      <td>4.591485</td>\n",
       "      <td>-0.370188</td>\n",
       "      <td>0.200660</td>\n",
       "      <td>-2.247352</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>1.093822</td>\n",
       "      <td>-0.204246</td>\n",
       "      <td>-0.427021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>3.078790</td>\n",
       "      <td>-2.807856</td>\n",
       "      <td>-3.082087</td>\n",
       "      <td>-2.657304</td>\n",
       "      <td>-1.939725</td>\n",
       "      <td>2.647739</td>\n",
       "      <td>-2.012444</td>\n",
       "      <td>0.094553</td>\n",
       "      <td>-0.028155</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>-2.901593</td>\n",
       "      <td>-1.216585</td>\n",
       "      <td>4.178510</td>\n",
       "      <td>-1.426573</td>\n",
       "      <td>-1.557683</td>\n",
       "      <td>2.061918</td>\n",
       "      <td>1.035576</td>\n",
       "      <td>0.932003</td>\n",
       "      <td>-0.135465</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>2.056384</td>\n",
       "      <td>-1.395916</td>\n",
       "      <td>0.425765</td>\n",
       "      <td>0.119901</td>\n",
       "      <td>-0.406810</td>\n",
       "      <td>-1.682385</td>\n",
       "      <td>-0.381383</td>\n",
       "      <td>-1.547569</td>\n",
       "      <td>-0.840144</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       projection0  projection1  projection2  projection3  projection4  \\\n",
       "0         0.706982     3.702191    -0.546160     1.083590    -1.282057   \n",
       "1        -4.753373    -3.257093    -2.983682    -1.244001    -1.880934   \n",
       "2         0.426475     5.168707    -0.215028     0.248895    -3.737808   \n",
       "3        -0.978410    -0.555503     1.147945    -0.324528    -0.997568   \n",
       "4        -4.878184    -3.244367    -4.723876    -0.850046    -1.923177   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "41995    -2.846328    -1.655570    -3.661467     0.658924    -1.528190   \n",
       "41996     1.776876     4.591485    -0.370188     0.200660    -2.247352   \n",
       "41997     3.078790    -2.807856    -3.082087    -2.657304    -1.939725   \n",
       "41998    -2.901593    -1.216585     4.178510    -1.426573    -1.557683   \n",
       "41999     2.056384    -1.395916     0.425765     0.119901    -0.406810   \n",
       "\n",
       "       projection5  projection6  projection7  projection8  label  \n",
       "0        -0.640238    -0.161646     0.711746     0.098052      1  \n",
       "1        -0.898564     0.114414    -1.097409     1.235790      0  \n",
       "2         0.168903     0.546867     0.164058    -0.314798      1  \n",
       "3        -0.858390     0.979497     1.846044    -0.207963      4  \n",
       "4        -2.093587     0.166724    -2.228554     0.999328      0  \n",
       "...            ...          ...          ...          ...    ...  \n",
       "41995    -0.680945     0.511808    -1.606290    -1.122931      0  \n",
       "41996    -0.005172     1.093822    -0.204246    -0.427021      1  \n",
       "41997     2.647739    -2.012444     0.094553    -0.028155      7  \n",
       "41998     2.061918     1.035576     0.932003    -0.135465      6  \n",
       "41999    -1.682385    -0.381383    -1.547569    -0.840144      9  \n",
       "\n",
       "[42000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''FDA projection on MNIST data'''\n",
    "\n",
    "\n",
    "\"Construct dataframe D2: 9 dimensional FDA projection of MNIST data.\"\n",
    "\n",
    "label_in_data= D0['label'] # labels\n",
    "dataval= D0.drop([\"label\"], axis =1) # features\n",
    "\n",
    "digits_labels = np.array(label_in_data)  # create array of labels in data\n",
    "#features = dataval.iloc[:, 0:dataval.shape[1]].values # create array of features.(dimensional array)\n",
    "\n",
    "\"fda\"\n",
    "classifier_fda = LDA(solver='svd', shrinkage = None, n_components=9) \n",
    "#by default, LDA uses 'svd' solver to help in escaping from getting 'LinAlgError: Singular matrix' error while computing eigen values and eigen vectors\n",
    "\n",
    "fda_data = classifier_fda .fit_transform(dataval, digits_labels)\n",
    "\n",
    "colnames = []\n",
    "for i in range(0,9):\n",
    "    colnames.append(\"projection\" + str(i))\n",
    "\n",
    "D2  = pd.DataFrame(data = fda_data, columns = colnames, dtype = None)\n",
    "D2['label'] = label_in_data  # append label column to projected data frame\n",
    "print(\"\\n\")\n",
    "print(\"D2 dataframe:\\n\")\n",
    "display(D2)  #  9 projections with last column as label column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f96b5",
   "metadata": {},
   "source": [
    "## Build a bayesian classifier on D1 dataset (with full covariance matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2946fe7b",
   "metadata": {},
   "source": [
    "#### Data Preparation \n",
    "\n",
    "Split the D1 data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58da6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_gnb_D1_train (predictors in train data): (29400, 9)\n",
      "shape of X_gnb_D1_test (predictors in test data): (12600, 9)\n",
      "shape of y_gnb_D1_train (response in train data): (29400,)\n",
      "shape of y_gnb_D1_test (response in test data): (12600,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_gnb_D1 = D1.drop('label', axis=1) # entire data excluding class labels.\n",
    "y_gnb_D1 =  D1['label'] # entire data with class labels only.\n",
    "X_gnb_D1_train, X_gnb_D1_test, y_gnb_D1_train, y_gnb_D1_test = train_test_split(X_gnb_D1, y_gnb_D1, test_size=0.3, random_state= 11915048, shuffle = True)\n",
    "print(\"shape of X_gnb_D1_train (predictors in train data):\", X_gnb_D1_train.shape)\n",
    "print(\"shape of X_gnb_D1_test (predictors in test data):\", X_gnb_D1_test.shape)\n",
    "print(\"shape of y_gnb_D1_train (response in train data):\", y_gnb_D1_train.shape)\n",
    "print(\"shape of y_gnb_D1_test (response in test data):\", y_gnb_D1_test.shape)\n",
    "\n",
    "\n",
    "\"convert train and test datasets to arrays \"\n",
    "X_gnb_D1_train_arr = np.array(X_gnb_D1_train) # convert train data to array\n",
    "y_gnb_D1_train_arr = np.array(y_gnb_D1_train)\n",
    "\n",
    "X_gnb_D1_test_arr = np.array(X_gnb_D1_test)\n",
    "y_gnb_D1_test_arr = np.array(y_gnb_D1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb61ab",
   "metadata": {},
   "source": [
    "#### Calculate prior probabilities\n",
    "\n",
    "compute prior probabilities (i.e. P(c) which is probability of each class label from 0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bc86051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels data size in train data:\n",
      " dict_items([(1, 3274), (3, 3061), (7, 3054), (2, 2968), (0, 2902), (9, 2874), (4, 2872), (6, 2864), (8, 2849), (5, 2682)])\n",
      "\n",
      "Prior Probabilities are:\n",
      " [0.09870748299319727, 0.11136054421768707, 0.10095238095238095, 0.1041156462585034, 0.09768707482993197, 0.09122448979591836, 0.09741496598639456, 0.10387755102040816, 0.09690476190476191, 0.09775510204081633]\n"
     ]
    }
   ],
   "source": [
    "c = y_gnb_D1_train.value_counts().to_dict() # we want to compute proportion of each class label in train data\n",
    "print(\"Class labels data size in train data:\\n\", c.items())\n",
    "#print(c[0], c[1])  # c[0] = 0, c[1] = 1..  which are class labels.\n",
    "prior_prob = np.ones(10) # 10 since we have 10 class labels in our data.\n",
    "for i in range(10):\n",
    "    prior_prob[i] = c[i]/y_gnb_D1_train.shape[0]  #proportion of each class in training data(in ascending order).\n",
    "\n",
    "prior_prob_list = list(prior_prob)\n",
    "print(\"\\nPrior Probabilities are:\\n\", prior_prob_list) # these are the prior probabilities of each class label . i.e. p(c1), p(c2).. p(c10) since we have 10 classes.\n",
    "#prior_prob.sum()  # sum should be equal to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874649e4",
   "metadata": {},
   "source": [
    "#### Function to form the gaussian distribution per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc33e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean and variance of each class and generate distribution.\n",
    "# mean array of each class is in 9 dimensions\n",
    "# covariance matrix  of each class is of 9*9 shape.\n",
    "# Function returns frozen object which contains mean and covariance of a particular class.\n",
    "def normdist(data):  # Data with 9 features.\n",
    "    var = np.cov(data.T)  # to compute covariance, we need to horizontally stack variables.\n",
    "    mean_array = []\n",
    "    for i in range(D1.shape[1]-1): # d1.shape-1->we have 9 features. loop will run 9 times and calc mean.\n",
    "        mu = np.mean(data[:,i])\n",
    "        mean_array.append(mu)\n",
    "    ma = np.array(mean_array)\n",
    "    #print(\"Mean array:\\n\", ma)\n",
    "    #print(\"Variance of X_class:\\n\", var)\n",
    "    distribution = multivariate_normal(ma, var)\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c85ed0",
   "metadata": {},
   "source": [
    "#### Predictions on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f38598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class labels for observations in train data are::\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        3\n",
       "2        3\n",
       "3        9\n",
       "4        5\n",
       "        ..\n",
       "29395    7\n",
       "29396    2\n",
       "29397    2\n",
       "29398    1\n",
       "29399    1\n",
       "Length: 29400, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class labels for observations in test data are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        6\n",
       "2        7\n",
       "3        5\n",
       "4        3\n",
       "        ..\n",
       "12595    8\n",
       "12596    1\n",
       "12597    2\n",
       "12598    3\n",
       "12599    0\n",
       "Length: 12600, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = sorted(list(c.keys())) \n",
    "# 'c' is a dictionary \n",
    "# keys: class labels(0 to 9); value: sample size counts per class\n",
    "#Predictions-on-train-and-test-data\n",
    "predictedvalues_traindata = pd.DataFrame() # assign empty dataframe to store predictions\n",
    "predictedvalues_testdata = pd.DataFrame()\n",
    "\n",
    "for i in range(D1.shape[1]):\n",
    "    X_class = np.array(X_gnb_D1_train[y_gnb_D1_train == labels[i]]) # subset on  basis of class label\n",
    "    norm_dist = normdist(X_class) # call normdist() function t0 get individual class distribution.\n",
    "    predictions_class = prior_prob_list[i]*norm_dist.pdf(X_gnb_D1_train_arr) # array of train data\n",
    "    predictions_class1 = prior_prob_list[i]*norm_dist.pdf(X_gnb_D1_test_arr) # array of test data\n",
    "    predictedvalues_traindata = pd.concat([predictedvalues_traindata, \n",
    "                                           pd.DataFrame(predictions_class)], axis = 1)\n",
    "    predictedvalues_testdata = pd.concat([predictedvalues_testdata, \n",
    "                                          pd.DataFrame(predictions_class1)], axis = 1)\n",
    "\n",
    "# assign column names as class labels (0 to 9) \n",
    "predictedvalues_traindata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "predictedvalues_testdata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] \n",
    "\n",
    "# get the max value in row and column name corresponding to that maximum rowvalue.\n",
    "predictedvalues_traindata = predictedvalues_traindata.idxmax(axis=1, skipna=True)\n",
    "\n",
    "print(\"predicted class labels for observations in train data are::\")\n",
    "display(predictedvalues_traindata)\n",
    "\n",
    "# get the max value in row and column name corresponding to that maximum rowvalue.\n",
    "predictedvalues_testdata = predictedvalues_testdata.idxmax(axis=1, skipna=True) \n",
    "print(\"predicted class labels for observations in test data are:\")\n",
    "display(predictedvalues_testdata)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ca9d5",
   "metadata": {},
   "source": [
    "#### Model accuracy on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed4d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data is:\n",
      "84.5986394557823 %\n",
      "\n",
      "Accuracy on test data is:\n",
      "84.19047619047619 %\n"
     ]
    }
   ],
   "source": [
    "\"Part 7 - Accuracy Measurements\"\n",
    "\n",
    "#train set accuracy:\n",
    "trainaccuracy_gnb_D1 = pd.DataFrame(list(zip(list(predictedvalues_traindata),\n",
    "                                             list(y_gnb_D1_train))), \n",
    "                                    columns =['predictedval_traindata', 'actuallabel_traindata'])\n",
    "\n",
    "trainaccuracy_gnb_D1['predictedval_traindata'] = trainaccuracy_gnb_D1['predictedval_traindata'].astype(int)\n",
    "\n",
    " # Take out rows where values in a row are same for all the columns. \n",
    "trueevents = trainaccuracy_gnb_D1[trainaccuracy_gnb_D1.apply(lambda x: min(x) == max(x), 1)]\n",
    "traindata_accuracy = (trueevents.shape[0]/y_gnb_D1_train.shape[0])*100\n",
    "print(\"Accuracy on train data is:\")\n",
    "print(str(traindata_accuracy) + \" %\")\n",
    "\n",
    "\n",
    "#test set accuracy-\n",
    "testaccuracy_gnb_D1 = pd.DataFrame(list(zip(list(predictedvalues_testdata), \n",
    "                                            list(y_gnb_D1_test))), \n",
    "                                   columns =['predictedval_testdata', 'actuallabel_testdata'])\n",
    "\n",
    "testaccuracy_gnb_D1['predictedval_testdata'] = testaccuracy_gnb_D1['predictedval_testdata'].astype(int)\n",
    "\n",
    "# Take out rows where values in a row are same for all the columns.\n",
    "trueevents1 = testaccuracy_gnb_D1[testaccuracy_gnb_D1.apply(lambda rowval: min(rowval) == max(rowval), 1)] \n",
    "\n",
    "testdata_accuracy = (trueevents1.shape[0]/y_gnb_D1_test.shape[0])*100\n",
    "\n",
    "print(\"\\nAccuracy on test data is:\")\n",
    "print(str(testdata_accuracy) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f569b0",
   "metadata": {},
   "source": [
    "## Build a bayesian classifier on D1 dataset (with diagonal covariance matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dbd066",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b9f0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_gnb_D1_train (predictors in train data): (29400, 9)\n",
      "shape of X_gnb_D1_test (predictors in test data): (12600, 9)\n",
      "shape of y_gnb_D1_train (response in train data): (29400,)\n",
      "shape of y_gnb_D1_test (response in test data): (12600,)\n"
     ]
    }
   ],
   "source": [
    "X_gnb_D1 = D1.drop('label', axis=1) # entire data excluding class labels.\n",
    "y_gnb_D1 =  D1['label'] # entire data with class labels only.\n",
    "X_gnb_D1_train, X_gnb_D1_test, y_gnb_D1_train, y_gnb_D1_test = train_test_split(X_gnb_D1, y_gnb_D1, test_size=0.3, random_state= 11915048, shuffle = True)\n",
    "print(\"shape of X_gnb_D1_train (predictors in train data):\", X_gnb_D1_train.shape)\n",
    "print(\"shape of X_gnb_D1_test (predictors in test data):\", X_gnb_D1_test.shape)\n",
    "print(\"shape of y_gnb_D1_train (response in train data):\", y_gnb_D1_train.shape)\n",
    "print(\"shape of y_gnb_D1_test (response in test data):\", y_gnb_D1_test.shape)\n",
    "\n",
    "\n",
    "\"convert train and test datasets to arrays\"\n",
    "X_gnb_D1_train_arr = np.array(X_gnb_D1_train) # convert train data to array\n",
    "y_gnb_D1_train_arr = np.array(y_gnb_D1_train)\n",
    "\n",
    "X_gnb_D1_test_arr = np.array(X_gnb_D1_test)\n",
    "y_gnb_D1_test_arr = np.array(y_gnb_D1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b4cd2",
   "metadata": {},
   "source": [
    "#### Calculate prior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d06bd57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels data size in train data:\n",
      "dict_items([(1, 3274), (3, 3061), (7, 3054), (2, 2968), (0, 2902), (9, 2874), (4, 2872), (6, 2864), (8, 2849), (5, 2682)])\n",
      "\n",
      "\n",
      "Prior Probabilities are:\n",
      "[0.09870748299319727, 0.11136054421768707, 0.10095238095238095, 0.1041156462585034, 0.09768707482993197, 0.09122448979591836, 0.09741496598639456, 0.10387755102040816, 0.09690476190476191, 0.09775510204081633]\n"
     ]
    }
   ],
   "source": [
    "# we want to compute proportion of each class label in train data\n",
    "c = y_gnb_D1_train.value_counts().to_dict() \n",
    "\n",
    "print(\"Class labels data size in train data:\")\n",
    "print(c.items())\n",
    "\n",
    "prior_prob = np.ones(10) # 10 since we have 10 class labels in our data.\n",
    "for i in range(10):\n",
    "    prior_prob[i] = c[i]/y_gnb_D1_train.shape[0]  #proportion of each class in training data(in ascending order).\n",
    "\n",
    "prior_prob_list = list(prior_prob)\n",
    "\n",
    "# these are the prior probabilities of each class label \n",
    "#. i.e. p(c1), p(c2).. p(c10) since we have 10 classes.\n",
    "#prior_prob.sum()  # sum should be equal to 1.0\n",
    "print(\"\\n\")\n",
    "print(\"Prior Probabilities are:\")\n",
    "print(prior_prob_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da525743",
   "metadata": {},
   "source": [
    "#### Function to form the gaussian distribution per class\n",
    "\n",
    "To obtain the diagonal covariance matrix, we use np.diag() that converts non diagonal elements to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cca7c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean and variance of each class and generate distribution.\n",
    "# mean array of each class is in 9 dimensions\n",
    "# covariance matrix  of each class is of 9*9 shape.\n",
    "# Function returns frozen object which contains mean and covariance of a particular class.\n",
    "\n",
    "def normdist(data):  # Data with 9 features.\n",
    "    var = np.cov(data.T)  # to compute covariance, we need to horizontally stack variables.\n",
    "    var = np.diag(np.diag(var))  # construct diagonal matrix(non diagonal elements are zero)\n",
    "    mean_array = []\n",
    "    for i in range(D1.shape[1]-1): # d1.shape-1 -> since we have 9 features. loop will run 9 times and calc mean.\n",
    "        mu = np.mean(data[:,i])\n",
    "        mean_array.append(mu)\n",
    "    ma = np.array(mean_array)\n",
    "    #print(\"Mean array:\\n\", ma)\n",
    "    #print(\"Variance of X_class:\\n\", var)\n",
    "    distribution = multivariate_normal(ma, var)\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99814d8",
   "metadata": {},
   "source": [
    "#### Predictions on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfce1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1        3\n",
       "2        3\n",
       "3        7\n",
       "4        3\n",
       "        ..\n",
       "29395    7\n",
       "29396    2\n",
       "29397    6\n",
       "29398    1\n",
       "29399    1\n",
       "Length: 29400, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test Set Predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        6\n",
       "2        7\n",
       "3        5\n",
       "4        3\n",
       "        ..\n",
       "12595    8\n",
       "12596    1\n",
       "12597    2\n",
       "12598    3\n",
       "12599    0\n",
       "Length: 12600, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = sorted(list(c.keys())) \n",
    "# 'c' is a dictionary with keys and values. \n",
    "#keys: class labels(0 to 9); value: sample size counts per class\n",
    "\n",
    "predictedvalues_traindata = pd.DataFrame() # store the predicted values from all the classes\n",
    "predictedvalues_testdata = pd.DataFrame()\n",
    "for i in range(D1.shape[1]):\n",
    "     # subset data for class label\n",
    "    X_class = np.array(X_gnb_D1_train[y_gnb_D1_train == labels[i]]) \n",
    "    norm_dist = normdist(X_class) # call normdist() function to get class distribution.\n",
    "    predictions_class = prior_prob_list[i]*norm_dist.pdf(X_gnb_D1_train_arr) # array of train data pred.\n",
    "    predictions_class1 = prior_prob_list[i]*norm_dist.pdf(X_gnb_D1_test_arr) # array of test data pred.\n",
    "    predictedvalues_traindata = pd.concat([predictedvalues_traindata, \n",
    "                                           pd.DataFrame(predictions_class)], axis = 1)\n",
    "    predictedvalues_testdata = pd.concat([predictedvalues_testdata,\n",
    "                                          pd.DataFrame(predictions_class1)], axis = 1)\n",
    "    \n",
    "\n",
    "# assign column names as class labels in our data\n",
    "predictedvalues_traindata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] \n",
    "\n",
    "# get the max value in row and column name corresponding to that maximum rowvalue.\n",
    "predictedvalues_traindata = predictedvalues_traindata.idxmax(axis=1, skipna=True) \n",
    "\n",
    "print(\"Train Set Predictions:\")\n",
    "display(predictedvalues_traindata)\n",
    "\n",
    "predictedvalues_testdata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] \n",
    "\n",
    "predictedvalues_testdata = predictedvalues_testdata.idxmax(axis=1, skipna=True) \n",
    "print(\"\\n\")\n",
    "print(\"Test Set Predictions:\")\n",
    "display(predictedvalues_testdata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acad88e",
   "metadata": {},
   "source": [
    "#### Model accuracy on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b604f87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data is:\n",
      "75.58503401360545 %\n",
      "\n",
      "Accuracy on test data is:\n",
      "75.51587301587301 %\n"
     ]
    }
   ],
   "source": [
    "#train set accuracy\n",
    "trainaccuracy_gnb_D1 = pd.DataFrame(list(zip(list(predictedvalues_traindata), \n",
    "                                             list(y_gnb_D1_train))), \n",
    "                                    columns =['predictedval_traindata', 'actuallabel_traindata'])\n",
    "trainaccuracy_gnb_D1['predictedval_traindata'] = trainaccuracy_gnb_D1['predictedval_traindata'].astype(int)\n",
    "\n",
    "\n",
    "trueevents = trainaccuracy_gnb_D1[trainaccuracy_gnb_D1.apply(lambda x: min(x) == max(x), 1)] \n",
    "traindata_accuracy = (trueevents.shape[0]/y_gnb_D1_train.shape[0])*100\n",
    "print(\"Accuracy on train data is:\")\n",
    "print(str(traindata_accuracy) + \" %\")\n",
    "\n",
    "#test set accuracy\n",
    "testaccuracy_gnb_D1 = pd.DataFrame(list(zip(list(predictedvalues_testdata), \n",
    "                                            list(y_gnb_D1_test))), \n",
    "                                   columns =['predictedval_testdata', 'actuallabel_testdata'])\n",
    "\n",
    "testaccuracy_gnb_D1['predictedval_testdata'] = testaccuracy_gnb_D1['predictedval_testdata'].astype(int)\n",
    "trueevents1 = testaccuracy_gnb_D1[testaccuracy_gnb_D1.apply(lambda rowval: min(rowval) == max(rowval), 1)] # Take out rows where values in a row are same for all the columns.\n",
    "testdata_accuracy = (trueevents1.shape[0]/y_gnb_D1_test.shape[0])*100\n",
    "print(\"\\nAccuracy on test data is:\")\n",
    "print(str(testdata_accuracy) + \" %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa6429e",
   "metadata": {},
   "source": [
    "## Build a bayesian classifier on D2 dataset (with full covariance matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb81794",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "Use D0 data i.e. MNIST digits data for implementing FDA and Bayesian Model on FDA 9-D output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c1e9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_gnb_D2_train (predictors in train data): (29400, 9)\n",
      "shape of X_gnb_D2_test (predictors in test data): (12600, 9)\n",
      "shape of y_gnb_D2_train (response in train data): (29400,)\n",
      "shape of y_gnb_D2_test (response in test data): (12600,)\n"
     ]
    }
   ],
   "source": [
    "X_gnb_D2 = D2.drop('label', axis=1) # entire data excluding class labels.\n",
    "y_gnb_D2 =  D2['label'] # entire data with class labels only.\n",
    "X_gnb_D2_train, X_gnb_D2_test, y_gnb_D2_train, y_gnb_D2_test = train_test_split(X_gnb_D2, y_gnb_D2, test_size=0.3, random_state= 11915048, shuffle = True)\n",
    "print(\"shape of X_gnb_D2_train (predictors in train data):\", X_gnb_D2_train.shape)\n",
    "print(\"shape of X_gnb_D2_test (predictors in test data):\", X_gnb_D2_test.shape)\n",
    "print(\"shape of y_gnb_D2_train (response in train data):\", y_gnb_D2_train.shape)\n",
    "print(\"shape of y_gnb_D2_test (response in test data):\", y_gnb_D2_test.shape)\n",
    "\n",
    "## convert D2 train data to array\n",
    "X_gnb_D2_train_arr = np.array(X_gnb_D2_train) \n",
    "y_gnb_D2_train_arr = np.array(y_gnb_D2_train)\n",
    "\n",
    "X_gnb_D2_test_arr = np.array(X_gnb_D2_test)\n",
    "y_gnb_D2_test_arr = np.array(y_gnb_D2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2c25d",
   "metadata": {},
   "source": [
    "#### Calculate prior probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3214ea5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels data size in train data:\n",
      "dict_items([(1, 3274), (3, 3061), (7, 3054), (2, 2968), (0, 2902), (9, 2874), (4, 2872), (6, 2864), (8, 2849), (5, 2682)])\n",
      "\n",
      "\n",
      "Prior Probabilities are:\n",
      "[0.09870748299319727, 0.11136054421768707, 0.10095238095238095, 0.1041156462585034, 0.09768707482993197, 0.09122448979591836, 0.09741496598639456, 0.10387755102040816, 0.09690476190476191, 0.09775510204081633]\n"
     ]
    }
   ],
   "source": [
    "# we want to compute proportion of each class label in D2 train data\n",
    "c = y_gnb_D2_train.value_counts().to_dict() \n",
    "\n",
    "print(\"Class labels data size in train data:\")\n",
    "print(c.items())\n",
    "#print(c[0], c[1])  # c[0] = 0, c[1] = 1..  which are class labels.\n",
    "prior_prob = np.ones(10) # 10 since we have 10 class labels in our data.\n",
    "for i in range(10):\n",
    "    prior_prob[i] = c[i]/y_gnb_D2_train.shape[0] \n",
    "    #proportion of each class in training data(in ascending order).\n",
    "\n",
    "prior_prob_list = list(prior_prob)\n",
    "print(\"\\n\")\n",
    "print(\"Prior Probabilities are:\")\n",
    "print(prior_prob_list) # these are the prior probabilities of each class label . i.e. p(c1), p(c2).. p(c10) since we have 10 classes.\n",
    "#prior_prob.sum()  # sum should be equal to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357decf5",
   "metadata": {},
   "source": [
    "#### Function to form the gaussian distribution per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc09dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean and variance of each class and generate distribution.\n",
    "# mean array of each class is in 9 dimensions\n",
    "# covariance matrix  of each class is of 9*9 shape.\n",
    "# Function returns frozen object which contains mean and covariance of a particular class.\n",
    "\n",
    "def normdist(data):  # Data with 9 features.Because each 'class' subset data has 9 columns(dimensions reduced to 9)\n",
    "    var = np.cov(data.T)  # to compute covariance, we need to horizontally stack variables.\n",
    "    mean_array = []\n",
    "    for i in range(D2.shape[1]-1): # d1.shape-1 -> since we have 9 features. loop will run 9 times and calc mean.\n",
    "        mu = np.mean(data[:,i])\n",
    "        mean_array.append(mu)\n",
    "    ma = np.array(mean_array)\n",
    "    #print(\"Mean array:\\n\", ma)\n",
    "    #print(\"Variance of X_class:\\n\", var)\n",
    "    distribution = multivariate_normal(ma, var)\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f615ec",
   "metadata": {},
   "source": [
    "#### Predictions on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b294a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on train data are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        3\n",
       "2        3\n",
       "3        9\n",
       "4        3\n",
       "        ..\n",
       "29395    7\n",
       "29396    2\n",
       "29397    2\n",
       "29398    1\n",
       "29399    1\n",
       "Length: 29400, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on test data are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        6\n",
       "2        7\n",
       "3        5\n",
       "4        3\n",
       "        ..\n",
       "12595    3\n",
       "12596    1\n",
       "12597    2\n",
       "12598    3\n",
       "12599    0\n",
       "Length: 12600, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = sorted(list(c.keys())) \n",
    "# 'c' is a dictionary with keys and values.\n",
    "# keys: class labels(0 to 9); value: sample size counts per class\n",
    "\n",
    "predictedvalues_traindata = pd.DataFrame() # store the predicted values from all the classes\n",
    "predictedvalues_testdata = pd.DataFrame()\n",
    "\n",
    "for i in range(len(D2['label'].unique())): # D[2].shape[1] =  10. # since\n",
    "    # subset on basis of class label\n",
    "    X_class = np.array(X_gnb_D2_train[y_gnb_D2_train == labels[i]]) \n",
    "    norm_dist = normdist(X_class) # call normdist() function to get class distribution\n",
    "    predictions_class = prior_prob_list[i]*norm_dist.pdf(X_gnb_D2_train_arr) # array of train data pred.\n",
    "    predictions_class1 = prior_prob_list[i]*norm_dist.pdf(X_gnb_D2_test_arr) # array of test data pred.\n",
    "    predictedvalues_traindata = pd.concat([predictedvalues_traindata, \n",
    "                                           pd.DataFrame(predictions_class)], axis = 1)\n",
    "    predictedvalues_testdata = pd.concat([predictedvalues_testdata, \n",
    "                                          pd.DataFrame(predictions_class1)], axis = 1)\n",
    "    \n",
    "    \n",
    "\n",
    "# assign column names = class labels in our data\n",
    "predictedvalues_traindata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] \n",
    "predictedvalues_traindata = predictedvalues_traindata.idxmax(axis=1, skipna=True) \n",
    "\n",
    "print(\"Predictions on train data are:\")\n",
    "display(predictedvalues_traindata)\n",
    "\n",
    "predictedvalues_testdata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] \n",
    "\n",
    "predictedvalues_testdata = predictedvalues_testdata.idxmax(axis=1, skipna=True) \n",
    "\n",
    "print(\"\\nPredictions on test data are:\")\n",
    "display(predictedvalues_testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddcdd8",
   "metadata": {},
   "source": [
    "#### Model accuracy on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63bb93d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on D2 train data:\n",
      "89.62244897959184 %\n",
      "\n",
      "\n",
      "Accuracy on D2 test data:\n",
      "89.9126984126984 %\n"
     ]
    }
   ],
   "source": [
    "trainaccuracy_gnb_D2 = pd.DataFrame(list(zip(list(predictedvalues_traindata), \n",
    "                                             list(y_gnb_D2_train))), \n",
    "                                    columns =['predictedval_traindata', 'actuallabel_traindata'])\n",
    "trainaccuracy_gnb_D2['predictedval_traindata'] = trainaccuracy_gnb_D2['predictedval_traindata'].astype(int)\n",
    "\n",
    "trueevents = trainaccuracy_gnb_D2[trainaccuracy_gnb_D2.apply(lambda rowval: min(rowval) == max(rowval), 1)] # Take out rows where values in a row are same for all the columns. \n",
    "traindata_accuracy = (trueevents.shape[0]/y_gnb_D2_train.shape[0])*100\n",
    "\n",
    "print(\"Accuracy on D2 train data:\")\n",
    "print(str(traindata_accuracy) + \" %\")\n",
    "\n",
    "\n",
    "testaccuracy_gnb_D2 = pd.DataFrame(list(zip(list(predictedvalues_testdata), \n",
    "                                            list(y_gnb_D2_test))), \n",
    "                                   columns =['predictedval_testdata', 'actuallabel_testdata'])\n",
    "testaccuracy_gnb_D2['predictedval_testdata'] = testaccuracy_gnb_D2['predictedval_testdata'].astype(int)\n",
    "trueevents1 = testaccuracy_gnb_D2[testaccuracy_gnb_D2.apply(lambda rowval: min(rowval) == max(rowval), 1)] # Take out rows where values in a row are same for all the columns.\n",
    "testdata_accuracy = (trueevents1.shape[0]/y_gnb_D2_test.shape[0])*100\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy on D2 test data:\")\n",
    "print(str(testdata_accuracy) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f353d",
   "metadata": {},
   "source": [
    "## Build a bayesian classifier on D2 dataset (with diagonal covariance matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbbf430",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1107a16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_gnb_D2_train (predictors in train data): (29400, 9)\n",
      "shape of X_gnb_D2_test (predictors in test data): (12600, 9)\n",
      "shape of y_gnb_D2_train (response in train data): (29400,)\n",
      "shape of y_gnb_D2_test (response in test data): (12600,)\n"
     ]
    }
   ],
   "source": [
    "X_gnb_D2 = D2.drop('label', axis=1) # entire data excluding class labels.\n",
    "y_gnb_D2 =  D2['label'] # entire data with class labels only.\n",
    "X_gnb_D2_train, X_gnb_D2_test, y_gnb_D2_train, y_gnb_D2_test = train_test_split(X_gnb_D2, y_gnb_D2, test_size=0.3, random_state= 11915048, shuffle = True)\n",
    "print(\"shape of X_gnb_D2_train (predictors in train data):\", X_gnb_D2_train.shape)\n",
    "print(\"shape of X_gnb_D2_test (predictors in test data):\", X_gnb_D2_test.shape)\n",
    "print(\"shape of y_gnb_D2_train (response in train data):\", y_gnb_D2_train.shape)\n",
    "print(\"shape of y_gnb_D2_test (response in test data):\", y_gnb_D2_test.shape)\n",
    "\n",
    "X_gnb_D2_train_arr = np.array(X_gnb_D2_train) # convert D2 train data to array\n",
    "y_gnb_D2_train_arr = np.array(y_gnb_D2_train)\n",
    "\n",
    "X_gnb_D2_test_arr = np.array(X_gnb_D2_test)\n",
    "y_gnb_D2_test_arr = np.array(y_gnb_D2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf97735",
   "metadata": {},
   "source": [
    "#### Calculate prior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41ed3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels data size in train data:\n",
      " dict_items([(1, 3274), (3, 3061), (7, 3054), (2, 2968), (0, 2902), (9, 2874), (4, 2872), (6, 2864), (8, 2849), (5, 2682)])\n",
      "\n",
      "\n",
      "Prior Probabilities are:\n",
      " [0.09870748299319727, 0.11136054421768707, 0.10095238095238095, 0.1041156462585034, 0.09768707482993197, 0.09122448979591836, 0.09741496598639456, 0.10387755102040816, 0.09690476190476191, 0.09775510204081633]\n"
     ]
    }
   ],
   "source": [
    "c = y_gnb_D2_train.value_counts().to_dict() # we want to compute proportion of each class label in D2 train data\n",
    "print(\"Class labels data size in train data:\\n\", c.items())\n",
    "#print(c[0], c[1])  # c[0] = 0, c[1] = 1..  which are class labels.\n",
    "prior_prob = np.ones(10) # 10 since we have 10 class labels in our data.\n",
    "for i in range(10):\n",
    "    prior_prob[i] = c[i]/y_gnb_D2_train.shape[0]  #proportion of each class in training data(in ascending order).\n",
    "\n",
    "prior_prob_list = list(prior_prob)\n",
    "# these are the prior probabilities of each class label\n",
    "#. i.e. p(c1), p(c2).. p(c10) since we have 10 classes.\n",
    "#prior_prob.sum()  # sum should be equal to 1.0\n",
    "print(\"\\n\")\n",
    "print(\"Prior Probabilities are:\\n\", prior_prob_list) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6860112",
   "metadata": {},
   "source": [
    "#### Function to form the gaussian distribution per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc22ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normdist(data):  # Data with 9 features.Because each 'class' subset data has 9 columns(dimensions reduced to 9)\n",
    "    var = np.cov(data.T)  # to compute covariance, we need to horizontally stack variables.\n",
    "    var = np.diag(np.diag(var))\n",
    "    mean_array = []\n",
    "    for i in range(D2.shape[1]-1): # d1.shape-1 -> since we have 9 features. loop will run 9 times and calc mean.\n",
    "        mu = np.mean(data[:,i])\n",
    "        mean_array.append(mu)\n",
    "    ma = np.array(mean_array)\n",
    "    #print(\"Mean array:\\n\", ma)\n",
    "    #print(\"Variance of X_class:\\n\", var)\n",
    "    distribution = multivariate_normal(ma, var)\n",
    "    return distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a462594d",
   "metadata": {},
   "source": [
    "#### Predictions on train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c2fb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on train data are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        3\n",
       "2        3\n",
       "3        9\n",
       "4        3\n",
       "        ..\n",
       "29395    7\n",
       "29396    2\n",
       "29397    2\n",
       "29398    1\n",
       "29399    1\n",
       "Length: 29400, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predictions on test data are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        6\n",
       "2        7\n",
       "3        5\n",
       "4        3\n",
       "        ..\n",
       "12595    3\n",
       "12596    1\n",
       "12597    2\n",
       "12598    3\n",
       "12599    0\n",
       "Length: 12600, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = sorted(list(c.keys())) \n",
    "# 'c' is a dictionary with keys are the class labels(0 to 9) and value is sample size count per class\n",
    "\n",
    "predictedvalues_traindata = pd.DataFrame() # store the predicted values from all the classes\n",
    "predictedvalues_testdata = pd.DataFrame()\n",
    "\n",
    "for i in range(len(D2['label'].unique())): # D[2].shape[1] =  10. # since\n",
    "    X_class = np.array(X_gnb_D2_train[y_gnb_D2_train == labels[i]]) # subset on  basis of class label\n",
    "    norm_dist = normdist(X_class) # call normdist() function to get class distribution\n",
    "    predictions_class = prior_prob_list[i]*norm_dist.pdf(X_gnb_D2_train_arr) # array of train data\n",
    "    predictions_class1 = prior_prob_list[i]*norm_dist.pdf(X_gnb_D2_test_arr) # array of test data\n",
    "    predictedvalues_traindata = pd.concat([predictedvalues_traindata, pd.DataFrame(predictions_class)],\n",
    "                                          axis = 1)\n",
    "    predictedvalues_testdata = pd.concat([predictedvalues_testdata, pd.DataFrame(predictions_class1)],\n",
    "                                         axis = 1)\n",
    "    \n",
    "\n",
    "predictedvalues_traindata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] \n",
    "\n",
    "predictedvalues_traindata = predictedvalues_traindata.idxmax(axis=1, skipna=True) \n",
    "print(\"Predictions on train data are:\")\n",
    "display(predictedvalues_traindata)\n",
    "\n",
    "predictedvalues_testdata.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"] # assign column names = class labels in our data\n",
    "predictedvalues_testdata = predictedvalues_testdata.idxmax(axis=1, skipna=True) # get the max value in row and column name corresponding to that maximum rowvalue.\n",
    "print(\"\\n\")\n",
    "print(\"Predictions on test data are:\")\n",
    "display(predictedvalues_testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edf5a5",
   "metadata": {},
   "source": [
    "#### Model accuracy on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0df1a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on D2 train data is:\n",
      "88.38095238095238 %\n",
      "\n",
      "Accuracy on D2 test data is:\n",
      "88.61111111111111 %\n"
     ]
    }
   ],
   "source": [
    "#train set accuracy\n",
    "\n",
    "trainaccuracy_gnb_D2 = pd.DataFrame(list(zip(list(predictedvalues_traindata), \n",
    "                                             list(y_gnb_D2_train))),\n",
    "                                    columns =['predictedval_traindata', 'actuallabel_traindata'])\n",
    "#trainaccuracy_gnb_D2 = trainaccuracy_gnb_D2.convert_objects(convert_numeric=True)\n",
    "trainaccuracy_gnb_D2['predictedval_traindata'] = trainaccuracy_gnb_D2['predictedval_traindata'].astype(int)\n",
    "trainaccuracy_gnb_D2\n",
    "trueevents = trainaccuracy_gnb_D2[trainaccuracy_gnb_D2.apply(lambda rowval: min(rowval) == max(rowval), 1)] # Take out rows where values in a row are same for all the columns. \n",
    "traindata_accuracy = (trueevents.shape[0]/y_gnb_D2_train.shape[0])*100\n",
    "print(\"Accuracy on D2 train data is:\")\n",
    "print(str(traindata_accuracy) + \" %\")\n",
    "\n",
    "\n",
    "#test set accuracy\n",
    "\n",
    "testaccuracy_gnb_D2 = pd.DataFrame(list(zip(list(predictedvalues_testdata), \n",
    "                                            list(y_gnb_D2_test))), \n",
    "                                   columns =['predictedval_testdata', 'actuallabel_testdata'])\n",
    "#testaccuracy_gnb_D2 = testaccuracy_gnb_D2.convert_objects(convert_numeric=True)\n",
    "testaccuracy_gnb_D2['predictedval_testdata'] = testaccuracy_gnb_D2['predictedval_testdata'].astype(int)\n",
    "trueevents1 = testaccuracy_gnb_D2[testaccuracy_gnb_D2.apply(lambda rowval: min(rowval) == max(rowval), 1)] # Take out rows where values in a row are same for all the columns.\n",
    "testdata_accuracy = (trueevents1.shape[0]/y_gnb_D2_test.shape[0])*100\n",
    "print(\"\\nAccuracy on D2 test data is:\")\n",
    "print(str(testdata_accuracy) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34324f7",
   "metadata": {},
   "source": [
    "#### After PCA, Accuracy Results for Bayesian on D1 dataframe -\n",
    "\n",
    "(Bayesian Classifier on D1 - (Considering Full  Covariance matrix)-\n",
    "train data accuracy -> 84.5986394557823 %\n",
    "test data accuracy -> 84.19047619047619 %\n",
    "\n",
    "(Bayesian Classifier on D1 - (Diagonal Covariance matrix)-\n",
    "train data accuracy -> 75.58503401360545 %\n",
    "test data accuracy -> 75.51587301587301 %\n",
    "\n",
    "<br>\n",
    "\n",
    "#### After FDA, Accuracy Results for Bayesian on D2 dataframe -\n",
    "\n",
    "(Bayesian Classifier on D2 - (Considering Full  Covariance matrix)-\n",
    "train data accuracy -> 89.62244897959184 %\n",
    "test data accuracy -> 89.9126984126984 %\n",
    "\n",
    "(Bayesian Classifier on D2 - (Considering Diagonal Covariance matrix)-\n",
    "train data accuracy -> 88.38095238095238 % \n",
    "test data accuracy -> 88.61111111111111 %\n",
    " \n",
    " Accuracy is lower when we considered diagonal covariance matrix since diagonal covariance matrix covers less portion of datapoints since it has a circle shape."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
